{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "y_train = to_categorical(y_train, 100)\n",
    "y_test = to_categorical(y_test, 100)\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(base_model)\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(100, activation='softmax'))\n",
    "\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 207ms/step - accuracy: 0.0083 - loss: 4.6742 - val_accuracy: 0.0101 - val_loss: 4.6052\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "    validation_data=(x_test, y_test),\n",
    "    epochs=epochs,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9800\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f'Test accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The filepath provided must end in `.keras` (Keras model format). Received: filepath=best_model.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Callbacks for learning rate scheduling and model checkpointing\u001b[39;00m\n\u001b[0;32m     45\u001b[0m lr_scheduler \u001b[38;5;241m=\u001b[39m callbacks\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 46\u001b[0m model_checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModelCheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest_model.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_best_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Train the model for 1 epoch\u001b[39;00m\n\u001b[0;32m     49\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\callbacks\\model_checkpoint.py:191\u001b[0m, in \u001b[0;36mModelCheckpoint.__init__\u001b[1;34m(self, filepath, monitor, verbose, save_best_only, save_weights_only, mode, save_freq, initial_value_threshold)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 191\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    192\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe filepath provided must end in `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    193\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(Keras model format). Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    194\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    195\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: The filepath provided must end in `.keras` (Keras model format). Received: filepath=best_model.h5"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load CIFAR-100 data\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "y_train = to_categorical(y_train, 100)\n",
    "y_test = to_categorical(y_test, 100)\n",
    "\n",
    "# Preprocess data\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    rotation_range=30\n",
    ")\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# Load ResNet50 model pre-trained on ImageNet, excluding the top (fully connected) layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "# Add custom top layers\n",
    "model = models.Sequential()\n",
    "model.add(base_model)\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(100, activation='softmax'))\n",
    "\n",
    "# Freeze the base model layers to prevent them from being updated during training\n",
    "base_model.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks for learning rate scheduling and model checkpointing\n",
    "lr_scheduler = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, verbose=1)\n",
    "model_checkpoint = callbacks.ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "# Train the model for 1 epoch\n",
    "batch_size = 64\n",
    "initial_epochs = 1\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "    validation_data=(x_test, y_test),\n",
    "    epochs=initial_epochs,\n",
    "    verbose=1,\n",
    "    callbacks=[lr_scheduler, model_checkpoint]\n",
    ")\n",
    "\n",
    "# Fine-tune the model for 1 more epoch\n",
    "base_model.trainable = True\n",
    "\n",
    "# Recompile the model with a lower learning rate\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Continue training for 1 epoch\n",
    "fine_tune_epochs = 1\n",
    "total_epochs = initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(\n",
    "    datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "    validation_data=(x_test, y_test),\n",
    "    epochs=total_epochs,\n",
    "    initial_epoch=history.epoch[-1],\n",
    "    verbose=1,\n",
    "    callbacks=[lr_scheduler, model_checkpoint]\n",
    ")\n",
    "\n",
    "# Load the best model\n",
    "model.load_weights('best_model.h5')\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f'Test accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
